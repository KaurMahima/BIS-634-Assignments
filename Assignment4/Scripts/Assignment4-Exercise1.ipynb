{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d881f2cc",
   "metadata": {},
   "source": [
    "## Exercise1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c860f6",
   "metadata": {},
   "source": [
    "Suppose we have a neural network for predicting the time between hospital readmissions for a certain subset of patients. Such a network would depends on many parameters, but for simplicity, let's assume there's only two parameters: a and b. Each parameter lies between 0 and 1 and represents the weights of two \"synapses\" in our model.\n",
    "\n",
    "Using the API at e.g.\n",
    "\n",
    "http://ramcdougal.com/cgi-bin/error_function.py?a=0.4&b=0.2 (Links to an external site.)\n",
    "\n",
    "one can find the prediction errors in arbitrary units of running our model with specified parameters (here a=0.4 and b=0.2, but you can change that).\n",
    "\n",
    "Implement a two-dimensional version of the gradient descent algorithm to find optimal choices of a and b. (7 points) (Optimal here means values that minimize the error.) See slides 12 for a 1-dimensional implementation of the algorithm. Explain how you estimate the gradient given that you cannot directly compute the derivative (3 points), identify any numerical choices -- including but not limited to stopping criteria -- you made (3 points), and justify why you think they were reasonable choices (3 points).\n",
    "\n",
    "It so happens that this error function has a local minimum and a global minimum. Find both locations (i.e. a, b values) querying the API as needed (5 points) and identify which corresponds to which (2 point). Briefly discuss how you would have tested for local vs global minima if you had not known how many minima there were. (2 points)\n",
    "\n",
    "Important: a key part of this problem is the implementation of the algorithm; do not use a Python library for gradient descent or copy gradient descent code from a website.\n",
    "\n",
    "(Disclaimer: the API function is not actually testing a neural network.)\n",
    "\n",
    "(Hint: remember the gradient is just a vector of 1D derivatives.)\n",
    "\n",
    "Note: Please be kind to my server. Do not systematically sweep through the parameter space. Using gradient descent will only require a moderate number of queries.\n",
    "\n",
    "Note: Explicitly specify a User-Agent header or you'll get a 406 error; i.e. do something like:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24ccec47",
   "metadata": {},
   "source": [
    ">>> import requests\n",
    ">>> a = 0.4\n",
    ">>> b = 0.2\n",
    ">>> float(requests.get(f\"http://ramcdougal.com/cgi-bin/error_function.py?a={a}&b={b}\", headers={\"User-Agent\": \"MyScript\"}).text)\n",
    "1.294915"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e29086",
   "metadata": {},
   "source": [
    "## Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d392b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing relevant libraries \n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aad707",
   "metadata": {},
   "source": [
    "#### Using the APIs to find the prediction errors in arbitrary units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df349a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a,b):\n",
    "\n",
    "    parameters = {\n",
    "        'a':a,\n",
    "        'b':b\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"MyScript\"\n",
    "    }\n",
    "    url = \"http://ramcdougal.com/cgi-bin/error_function.py\"\n",
    "    result = requests.get(url,params = parameters,headers=headers)\n",
    "    return float(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "137f682d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.294915"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(0.4, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2712c09",
   "metadata": {},
   "source": [
    "#### Function for derivative of f(a,b) with respect to a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b31ef9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivativeA(a, b, h):\n",
    "    return (f(a + h,b) - f(a,b))/h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf70c5",
   "metadata": {},
   "source": [
    "#### Function for derivative of f(a,b) with respect to b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "230dd592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DerivativeB(a, b, h):\n",
    "    return (f(a,b + h) - f(a,b))/h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910de9e1",
   "metadata": {},
   "source": [
    "#### 2D Vector containing the derivative of both A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceac5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalderivative(a, b, h):\n",
    "    return np.array([derivativeA(a, b, h), DerivativeB(a, b, h)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80788ba1",
   "metadata": {},
   "source": [
    "#### Two-dimensional version of the gradient descent algorithm to find optimal choices of a and b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4363ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(init_step, alpha, h = 1e-4, tolerance = 1e-8):\n",
    "    previous_step_size = init_step - 10 * tolerance\n",
    "    step = init_step\n",
    "     \n",
    "    #values for the gradient descent algorithm \n",
    "    step_a = []\n",
    "    step_b = []\n",
    "    end_result = []\n",
    "    n_iter = 0\n",
    "    max_iter = 1000\n",
    "    while norm(step - previous_step_size) > tolerance and n_iter < max_iter :\n",
    "        previous_step_size = step\n",
    "        step = step - alpha * finalderivative(step[0], step[1], h)\n",
    "        step_a.append(step[0])\n",
    "        step_b.append(step[1])\n",
    "        end_result.append(f(step[0], step[1]))\n",
    "        n_iter+=1\n",
    "        \n",
    "    print (f\"The minimum value {end_result[-1]} occurs at :\")\n",
    "    print (f\"a = {step_a[-1]}, b = {step_b[-1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbcabf7",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b0d2808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value 1.100000005 occurs at :\n",
      "a = 0.21595000000038012, b = 0.6889500399996086.\n"
     ]
    }
   ],
   "source": [
    "gradient_descent(np.array([0.001, 0.999]), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2573fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value 1.000000015 occurs at :\n",
      "a = 0.7119500099997124, b = 0.1689500000000278.\n"
     ]
    }
   ],
   "source": [
    "gradient_descent(np.array([0.999, 0.001]), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15eca519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value 1.100000005 occurs at :\n",
      "a = 0.21595000000015233, b = 0.6889499600005788.\n"
     ]
    }
   ],
   "source": [
    "gradient_descent(np.array([0.09, 0.05]), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b087ee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value 1.100000005 occurs at :\n",
      "a = 0.2159499999995262, b = 0.6889499599998726.\n"
     ]
    }
   ],
   "source": [
    "gradient_descent(np.array([0.05, 0.09]), 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c428ec",
   "metadata": {},
   "source": [
    "#### Gradient Descent is an optimization algorithm to find the minimum of a function. We start with a random point on the function and move in the negative direction of the gradient of the function to reach the local/global minima.\n",
    "\n",
    "#### Qa. Explain how you estimate the gradient given that you cannot directly compute the derivative? \n",
    "Ans.  I used the definition of derivative f'(x) = f(x + h) - f(x)/h and partial derivative function to estimate the gradient function. The parameter value (h) was set to be small. \n",
    "\n",
    "Reference: https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/the-gradient and the cheatsheet provided. \n",
    "\n",
    "\n",
    "#### Qb. Identify any numerical choices -- including but not limited to stopping criteria -- you made (3 points), and justify why you think they were reasonable choices (3 points).\n",
    "\n",
    "Ans. Learning Rate: It determines how fast or slow we will move towards the optimal weights. If the learning rate is very large we will skip the optimal solution. If it is too small we will need too many iterations to converge to the best values.The obvious way to find a desirable or optimal learning rate is through trial and error. For the gradient descent the default learning rate is 0.01 or 0.1. Therefore, I have used 0.01 as the alpha. \n",
    "\n",
    "Stopping Criteria: I have set the max iteration to 1000. It makes the algorithm to stop iterating and return the result before max_iter is reached if the vector update in the current iteration is less than or equal to tolerance. \n",
    "\n",
    "\n",
    "#### Qc. Identify which corresponds to which (2 point). Briefly discuss how you would have tested for local vs global minima if you had not known how many minima there were. (2 points)\n",
    "\n",
    "Ans. In a gradient descent model the smallest value is global minimum while other points are local minimum. Trying different combinations of the value while keeping the other parameters same would help in identifying the local vs global minima. Aso, gradient descent is able to find local minima most of the time and not global minima because the gradient does not point in the direction of the steepest descent. Current techniques to find global minima either require extremely high iteration counts or a large number of random restarts for good performance.The global minima is 1.000000015 which occurs at : a = 0.7119500099997124, b = 0.1689500000000278 while the local minima is 1.100000005 which occurs at : a = 0.21595000000038012, b = 0.6889500399996086 or at a = 0.2159499999995262, b = 0.6889499599998726."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
